# üèóÔ∏è System Architecture ‚Äì Piper TTS Personalization Engine

This document explains the full architecture of the **Personalized Speech Learning System**, created on top of **Piper TTS**.

It includes:
- High-level system architecture  
- Module responsibilities  
- Data flow pipeline  
- Personalization workflow  
- Integration points with Piper  

---

# üîπ 1. High-Level Architecture Overview

```
+-------------------------------------------------------------+
|                        User Audio                           |
+-------------------------------------------------------------+
                              ‚îÇ
                              ‚ñº
+-------------------------------------------------------------+
|                    Audio Preprocessor                       |
|  - Noise reduction                                           |
|  - Silence trimming                                          |
|  - Normalization                                             |
|  - Resampling                                                |
+-------------------------------------------------------------+
                              ‚îÇ
                              ‚ñº
+-------------------------------------------------------------+
|                    Feature Extractor                        |
|  - Pitch / Energy                                            |
|  - Speaking rate / pauses                                    |
|  - Emotion spectral features                                 |
+-------------------------------------------------------------+
                              ‚îÇ
                              ‚ñº
+-------------------------------------------------------------+
|                       Pattern Learner                       |
|  Learns:                                                     |
|    - Speaking patterns                                       |
|    - Prosody / stress patterns                               |
|    - Emotion tendencies                                      |
+-------------------------------------------------------------+
                              ‚îÇ
                              ‚ñº
+-------------------------------------------------------------+
|               Voice Profile Manager (JSON/YAML)             |
|  Stores learned profile using user ID                        |
+-------------------------------------------------------------+
                              ‚îÇ
                              ‚ñº
+-------------------------------------------------------------+
|                      Synthesis Adapter                      |
|  Applies personalization to Piper output:                    |
|    - Pitch shift                                             |
|    - Speed adjustment                                        |
|    - Pause insertion                                         |
|    - Emotion coloration                                      |
+-------------------------------------------------------------+
                              ‚îÇ
                              ‚ñº
+-------------------------------------------------------------+
|                     Final Audio Output                      |
+-------------------------------------------------------------+
```

---

# üîπ 2. Component Responsibilities

### **AudioPreprocessor**
- Loads audio  
- Removes noise (Wiener filter)  
- Removes silence  
- Normalizes amplitude  
- Resamples to 22,050 Hz  

### **FeatureExtractor**
Extracts:
- Speaking rate  
- Pause statistics  
- Pitch mean + variance  
- Energy  
- Spectral emotion features  

### **PatternLearner**
Learns:
- Speaking patterns  
- Prosody (pitch, energy)  
- Emotional tendencies  

### **VoiceProfileManager**
- Saves profiles as JSON  
- Loads profiles  
- Lists profile versions  
- Organizes profiles by user  

### **SynthesisAdapter**
Applies personalization to Piper-generated audio:
- Pitch shift based on user pitch mean  
- Speed modifications from speaking rate  
- Pause insertion from user pauses  
- Emotion coloration from spectral features  

---

# üîπ 3. End-to-End Data Flow

```
User Audio
    ‚Üí Preprocessor
    ‚Üí FeatureExtractor
    ‚Üí PatternLearner
    ‚Üí VoiceProfile (JSON)
    ‚Üí Piper TTS Output
    ‚Üí SynthesisAdapter
    ‚Üí Final Personalized Voice
```

---

# üîπ 4. Integration with Piper TTS

### 1Ô∏è‚É£ Piper generates base speech audio:

```
piper --model en_US-amy-medium.onnx --output_file base.wav
```

### 2Ô∏è‚É£ The SynthesisAdapter modifies this audio:
- Pitch  
- Speed / Rate  
- Pauses  
- Emotional tone  

### 3Ô∏è‚É£ Output saved as:

```
output.wav
```

---

# üîπ 5. Runtime Workflow (Training)

### Command:

```
python main.py train --user_audio path.wav --user_id prakash
```

### Steps:
1. Preprocess audio  
2. Extract features  
3. Learn patterns  
4. Save profile JSON  

---

# üîπ 6. Runtime Workflow (Synthesis)

### Command:

```
python main.py synthesize --text "Hello" --profile profiles/prakash_profile.json
```

### Steps:
1. Piper generates neutral audio  
2. Synthesis adapter personalizes the audio  
3. Saves final output  

---

# üîπ 7. Notes and Limitations
- Not a neural fine-tune of Piper (statistical personalization)  
- Requires clean audio for high-quality results  
- Emotion processing is simplified  
- Works offline and runs fast  

---

# ‚úÖ END OF ARCHITECTURE.md
